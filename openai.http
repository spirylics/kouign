@baseUrl = http://localhost:9090
@version = v1
@apiUrl = {{baseUrl}}/api/{{version}}

### health
GET {{baseUrl}}/actuator/health
Accept: application/json

### get models
GET {{apiUrl}}/models
Accept: application/json

### chat completions
POST {{apiUrl}}/chat/completions
Content-Type: application/json
Accept: application/json

{
  "model": "qwen3-coder:30b",
  "messages": [
    {
      "role": "user",
      "content": "1 + 2 = ?"
    }
  ],
  "temperature": 0.7,
  "max_tokens": 100
}

### qwen
POST http://localhost/ai/ollama/v1/chat/completions
Content-Type: application/json
Accept: application/json

{
  "model": "qwen3-coder:30b",
  "messages": [
    {
      "role": "user",
      "content": "1 + 1 = ?"
    }
  ],
  "temperature": 1.0,
  "max_tokens": 100
}

### qwen stream
POST http://localhost/ai/ollama/v1/chat/completions
Content-Type: application/json
Accept: application/json

{
  "model": "qwen3-coder:30b",
  "messages": [
    {
      "role": "system",
      "content": "You are an code reviewer assistant."
    },
    {
      "role": "user",
      "content": "Java is better than C#, right ?"
    }
  ],
  "temperature": 0.10000000149011612,
  "stream": true,
  "max_tokens": 4096,
  "max_completion_tokens": 8192,
  "frequency_penalty": 0.0,
  "presence_penalty": 0.6
}
